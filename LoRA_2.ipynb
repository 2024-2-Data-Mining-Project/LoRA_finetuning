{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37sXC-9VSnqU"
      },
      "source": [
        "> rank, alpha, dropout 설정은 더 찾아봐야 해요\n",
        "\n",
        "> Epoch설정도 validation이랑 같이 돌려서 설정해야 함요."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jh10Ez9Aabe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_unique_df.csv\")"
      ],
      "metadata": {
        "id": "CwXZrGoESo9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FnoR6hkUYbGO",
        "outputId": "576866bc-c83b-48e8-b3b1-08f47ce69024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               id   title   author translator  publish_year period  \\\n",
              "0     P0991-01-47      벼락   빅토르 위고        윤세홍          2018     근대   \n",
              "1     P0991-01-47      벼락   빅토르 위고        윤세홍          2018     근대   \n",
              "2     P0991-01-47      벼락   빅토르 위고        윤세홍          2018     근대   \n",
              "3     P0991-01-47      벼락   빅토르 위고        윤세홍          2018     근대   \n",
              "4     P0991-01-47      벼락   빅토르 위고        윤세홍          2018     근대   \n",
              "...           ...     ...      ...        ...           ...    ...   \n",
              "9487  P1290-01-50  쓸쓸한 시절  이상화/이장희        장현숙          2014     현대   \n",
              "9488  P1290-01-50  쓸쓸한 시절  이상화/이장희        장현숙          2014     현대   \n",
              "9489  P1290-01-50  쓸쓸한 시절  이상화/이장희        장현숙          2014     현대   \n",
              "9490  P1290-01-50  쓸쓸한 시절  이상화/이장희        장현숙          2014     현대   \n",
              "9491  P1290-01-50  쓸쓸한 시절  이상화/이장희        장현숙          2014     현대   \n",
              "\n",
              "                                            origin_text  sentence_count  \n",
              "0      나는 가끔 하늘에서 거대한 붉은빛이 내게로 달려드는, 이 엄숙하고 놀라운 일을 겪는다.               6  \n",
              "1     오, 사색가여, 그대처럼, 이사야의 슬픈 마음이 노엽게 만들고 증오했던, 숭고한 벼...               6  \n",
              "2                               섬광은 내 외침 소리, 벼락은 내 목소리.               6  \n",
              "3                      그대가 왕들에게 하는 것처럼, 나는 암초에 대고 노호한다.               6  \n",
              "4                               나는 무섭고 갑작스러운, 하늘나라의 경적.               6  \n",
              "...                                                 ...             ...  \n",
              "9487                  어느덧 가을은 깊어 들이든 뫼이든 숲이든 모두 파리해 있다.               5  \n",
              "9488                               언덕 우에 오뚝히 서서 개가 짖는다.               5  \n",
              "9489                                          날카롭게 짖는다.               5  \n",
              "9490                     빈 들에 마른 잎 태우는 연기 가늘게 가늘게 떠오른다.               5  \n",
              "9491                     그대여 우리들 머리 숙이고 고요히 생각할 그때가 왔다.               5  \n",
              "\n",
              "[9492 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93e27336-6222-490e-a835-f3956239de09\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>translator</th>\n",
              "      <th>publish_year</th>\n",
              "      <th>period</th>\n",
              "      <th>origin_text</th>\n",
              "      <th>sentence_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P0991-01-47</td>\n",
              "      <td>벼락</td>\n",
              "      <td>빅토르 위고</td>\n",
              "      <td>윤세홍</td>\n",
              "      <td>2018</td>\n",
              "      <td>근대</td>\n",
              "      <td>나는 가끔 하늘에서 거대한 붉은빛이 내게로 달려드는, 이 엄숙하고 놀라운 일을 겪는다.</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P0991-01-47</td>\n",
              "      <td>벼락</td>\n",
              "      <td>빅토르 위고</td>\n",
              "      <td>윤세홍</td>\n",
              "      <td>2018</td>\n",
              "      <td>근대</td>\n",
              "      <td>오, 사색가여, 그대처럼, 이사야의 슬픈 마음이 노엽게 만들고 증오했던, 숭고한 벼...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P0991-01-47</td>\n",
              "      <td>벼락</td>\n",
              "      <td>빅토르 위고</td>\n",
              "      <td>윤세홍</td>\n",
              "      <td>2018</td>\n",
              "      <td>근대</td>\n",
              "      <td>섬광은 내 외침 소리, 벼락은 내 목소리.</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P0991-01-47</td>\n",
              "      <td>벼락</td>\n",
              "      <td>빅토르 위고</td>\n",
              "      <td>윤세홍</td>\n",
              "      <td>2018</td>\n",
              "      <td>근대</td>\n",
              "      <td>그대가 왕들에게 하는 것처럼, 나는 암초에 대고 노호한다.</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P0991-01-47</td>\n",
              "      <td>벼락</td>\n",
              "      <td>빅토르 위고</td>\n",
              "      <td>윤세홍</td>\n",
              "      <td>2018</td>\n",
              "      <td>근대</td>\n",
              "      <td>나는 무섭고 갑작스러운, 하늘나라의 경적.</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9487</th>\n",
              "      <td>P1290-01-50</td>\n",
              "      <td>쓸쓸한 시절</td>\n",
              "      <td>이상화/이장희</td>\n",
              "      <td>장현숙</td>\n",
              "      <td>2014</td>\n",
              "      <td>현대</td>\n",
              "      <td>어느덧 가을은 깊어 들이든 뫼이든 숲이든 모두 파리해 있다.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9488</th>\n",
              "      <td>P1290-01-50</td>\n",
              "      <td>쓸쓸한 시절</td>\n",
              "      <td>이상화/이장희</td>\n",
              "      <td>장현숙</td>\n",
              "      <td>2014</td>\n",
              "      <td>현대</td>\n",
              "      <td>언덕 우에 오뚝히 서서 개가 짖는다.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9489</th>\n",
              "      <td>P1290-01-50</td>\n",
              "      <td>쓸쓸한 시절</td>\n",
              "      <td>이상화/이장희</td>\n",
              "      <td>장현숙</td>\n",
              "      <td>2014</td>\n",
              "      <td>현대</td>\n",
              "      <td>날카롭게 짖는다.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9490</th>\n",
              "      <td>P1290-01-50</td>\n",
              "      <td>쓸쓸한 시절</td>\n",
              "      <td>이상화/이장희</td>\n",
              "      <td>장현숙</td>\n",
              "      <td>2014</td>\n",
              "      <td>현대</td>\n",
              "      <td>빈 들에 마른 잎 태우는 연기 가늘게 가늘게 떠오른다.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9491</th>\n",
              "      <td>P1290-01-50</td>\n",
              "      <td>쓸쓸한 시절</td>\n",
              "      <td>이상화/이장희</td>\n",
              "      <td>장현숙</td>\n",
              "      <td>2014</td>\n",
              "      <td>현대</td>\n",
              "      <td>그대여 우리들 머리 숙이고 고요히 생각할 그때가 왔다.</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9492 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93e27336-6222-490e-a835-f3956239de09')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93e27336-6222-490e-a835-f3956239de09 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93e27336-6222-490e-a835-f3956239de09');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f6b33e4-2595-44cb-9cf7-f4f1b72a8f16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f6b33e4-2595-44cb-9cf7-f4f1b72a8f16')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f6b33e4-2595-44cb-9cf7-f4f1b72a8f16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b5c695bd-5e29-44ca-ac2a-1a5879f982ca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b5c695bd-5e29-44ca-ac2a-1a5879f982ca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9492,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1890,\n        \"samples\": [\n          \"P0135-01-49\",\n          \"P0280-01-42\",\n          \"P1327-01-35\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1338,\n        \"samples\": [\n          \"\\ub098\\ub294 \\uace0\\ud5a5 \\ub545\\uc5d0\",\n          \"\\ubb18\\ube44\\uba85\",\n          \"\\ud5ec\\ub80c\\uc5d0\\uac8c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 125,\n        \"samples\": [\n          \"\\ud29c\\uccb4\\ud504, \\ud45c\\ub3c4\\ub974 \\uc774\\ubc14\\ub178\\ube44\\uce58\",\n          \"\\ub178\\ub95c \\uc678\",\n          \"\\uace0\\uc11d\\uaddc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translator\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"\\uae40\\uc9c4\\ud76c\",\n          \"\\uc724\\uc138\\ud64d\",\n          \"\\uc8fc\\uae30\\ud3c9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publish_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 1,\n        \"max\": 2021,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          2010,\n          2017,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"period\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\\ud604\\ub300\",\n          \"\\uc911\\uc138\",\n          \"\\uadfc\\ub300\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"origin_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9142,\n        \"samples\": [\n          \"\\ubd04 \\ud558\\ub298\\uc740 \\ud654\\ucc3d\\ud558\\uace0 \\ubc1d\\uc740 \\ud0dc\\uc591\\uc740 \\ub530\\ub73b\\ud55c\\ub370, \\ubaa8\\uc774 \\ucabc\\uace0 \\uc0d8\\ubb3c \\ub9c8\\uc2dc\\ub2c8 \\ud798\\ucc2c \\uae30\\uc6b4\\uc774 \\uac00\\ub4dd\\ud574 \\uc218\\ucef7\\uc784\\uc744 \\ub2e4\\ud22c\\uba70 \\uc8fd\\uae30\\ub85c \\uc2f8\\uc6b0\\ub2e4 \\uace0\\uc6b4 \\ubaa9\\uc774 \\ubd80\\ub7ec\\uc84c\\ub124.\",\n          \"\\ub2e4\\uc2dc \\ub178\\ub798\\ud558\\uace0 \\ub208\\uc5ec\\uaca8 \\uc7a1\\uc544 \\ubcf4\\uc544\\ub3c4 \\uc815\\ub9d0 \\uc5b4\\uca54 \\uc218 \\uc5c6\\uc5b4, \\ubc29\\uae08 \\ud540 \\uaf43\\uc774 \\ubc8c\\uc368 \\ub5a8\\uc5b4\\uc9c0\\ub2c8 \\uc2ac\\ud514\\uc744 \\uc9c0\\uc6b0\\uc9c0 \\ubabb\\ud558\\ub124.\",\n          \"\\uadf8 \\uafc8\\uc774 \\uc5b4\\ub5a4 \\uac83\\uc778\\uc9c0\\ub294 \\ub3c5\\uc790 \\uc2a4\\uc2a4\\ub85c\\ub3c4 \\uc27d\\uac8c \\uc0c1\\uc0c1\\ud560 \\uc218 \\uc788\\uc744 \\ud130\\uc774\\ub2c8 \\ub9d0\\uc774\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          6,\n          9,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zy6KfOR1SnqV",
        "outputId": "bb5269d0-20b6-4735-f047-274ab85e0303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 1's loss: 8.875059127807617\n",
            "batch 2's loss: 8.91606616973877\n",
            "batch 3's loss: 8.828226089477539\n",
            "batch 4's loss: 8.915282249450684\n",
            "batch 5's loss: 8.873071670532227\n",
            "batch 6's loss: 8.762006759643555\n",
            "batch 7's loss: 8.749157905578613\n",
            "batch 8's loss: 8.724837303161621\n",
            "batch 9's loss: 8.664798736572266\n",
            "batch 10's loss: 8.645851135253906\n",
            "batch 11's loss: 8.636205673217773\n",
            "batch 12's loss: 8.747366905212402\n",
            "batch 13's loss: 8.552626609802246\n",
            "batch 14's loss: 8.443209648132324\n",
            "batch 15's loss: 8.456201553344727\n",
            "batch 16's loss: 8.458111763000488\n",
            "batch 17's loss: 8.383665084838867\n",
            "batch 18's loss: 8.359495162963867\n",
            "batch 19's loss: 8.439655303955078\n",
            "batch 20's loss: 8.462103843688965\n",
            "batch 21's loss: 8.376684188842773\n",
            "batch 22's loss: 8.360631942749023\n",
            "batch 23's loss: 8.236004829406738\n",
            "batch 24's loss: 8.428470611572266\n",
            "batch 25's loss: 8.143943786621094\n",
            "batch 26's loss: 8.104316711425781\n",
            "batch 27's loss: 8.103841781616211\n",
            "batch 28's loss: 8.188817024230957\n",
            "batch 29's loss: 7.770852088928223\n",
            "batch 30's loss: 7.953134059906006\n",
            "batch 31's loss: 7.834649562835693\n",
            "batch 32's loss: 7.746240615844727\n",
            "batch 33's loss: 7.599493026733398\n",
            "batch 34's loss: 7.568782329559326\n",
            "batch 35's loss: 7.544824123382568\n",
            "batch 36's loss: 7.821351528167725\n",
            "batch 37's loss: 7.486447334289551\n",
            "batch 38's loss: 7.561215877532959\n",
            "batch 39's loss: 7.513341426849365\n",
            "batch 40's loss: 7.121884346008301\n",
            "batch 41's loss: 7.144566059112549\n",
            "batch 42's loss: 7.1060285568237305\n",
            "batch 43's loss: 7.2048211097717285\n",
            "batch 44's loss: 6.871731758117676\n",
            "batch 45's loss: 6.611464500427246\n",
            "batch 46's loss: 6.497754096984863\n",
            "batch 47's loss: 6.9989190101623535\n",
            "batch 48's loss: 6.2914862632751465\n",
            "batch 49's loss: 6.530992031097412\n",
            "batch 50's loss: 6.945962905883789\n",
            "batch 51's loss: 5.608546257019043\n",
            "batch 52's loss: 6.214810848236084\n",
            "batch 53's loss: 5.629695892333984\n",
            "batch 54's loss: 5.563212871551514\n",
            "batch 55's loss: 5.565732955932617\n",
            "batch 56's loss: 5.7191162109375\n",
            "batch 57's loss: 5.1454973220825195\n",
            "batch 58's loss: 5.279768943786621\n",
            "batch 59's loss: 6.0173115730285645\n",
            "batch 60's loss: 4.6157612800598145\n",
            "batch 61's loss: 4.025311470031738\n",
            "batch 62's loss: 5.029743671417236\n",
            "batch 63's loss: 4.348944187164307\n",
            "batch 64's loss: 4.923299312591553\n",
            "batch 65's loss: 4.647876739501953\n",
            "batch 66's loss: 4.387889862060547\n",
            "batch 67's loss: 3.806379795074463\n",
            "batch 68's loss: 3.3544507026672363\n",
            "batch 69's loss: 4.781207084655762\n",
            "batch 70's loss: 4.469354629516602\n",
            "batch 71's loss: 3.339262008666992\n",
            "batch 72's loss: 3.5493462085723877\n",
            "batch 73's loss: 3.7106761932373047\n",
            "batch 74's loss: 4.654073238372803\n",
            "batch 75's loss: 2.565289258956909\n",
            "batch 76's loss: 3.5395169258117676\n",
            "batch 77's loss: 2.9638917446136475\n",
            "batch 78's loss: 2.525453805923462\n",
            "batch 79's loss: 2.258173704147339\n",
            "batch 80's loss: 2.3662962913513184\n",
            "batch 81's loss: 1.7636480331420898\n",
            "batch 82's loss: 1.4966305494308472\n",
            "batch 83's loss: 0.9158517122268677\n",
            "batch 84's loss: 2.673250198364258\n",
            "batch 85's loss: 2.6809849739074707\n",
            "batch 86's loss: 2.8088443279266357\n",
            "batch 87's loss: 1.978600025177002\n",
            "batch 88's loss: 1.4598371982574463\n",
            "batch 89's loss: 1.5876460075378418\n",
            "batch 90's loss: 2.274010181427002\n",
            "batch 91's loss: 3.4670040607452393\n",
            "batch 92's loss: 2.612316370010376\n",
            "batch 93's loss: 1.726841926574707\n",
            "batch 94's loss: 1.2615175247192383\n",
            "batch 95's loss: 2.1168839931488037\n",
            "batch 96's loss: 2.2059404850006104\n",
            "batch 97's loss: 2.274465322494507\n",
            "batch 98's loss: 1.6582393646240234\n",
            "batch 99's loss: 0.647516131401062\n",
            "batch 100's loss: 0.896629810333252\n",
            "batch 101's loss: 3.3260960578918457\n",
            "batch 102's loss: 2.791590929031372\n",
            "batch 103's loss: 1.5693682432174683\n",
            "batch 104's loss: 2.09446120262146\n",
            "batch 105's loss: 1.7944834232330322\n",
            "batch 106's loss: 1.9946181774139404\n",
            "batch 107's loss: 2.0724897384643555\n",
            "batch 108's loss: 2.5794854164123535\n",
            "batch 109's loss: 0.8314176797866821\n",
            "batch 110's loss: 1.7607470750808716\n",
            "batch 111's loss: 1.8134461641311646\n",
            "batch 112's loss: 2.516911029815674\n",
            "batch 113's loss: 2.5308539867401123\n",
            "batch 114's loss: 3.3359930515289307\n",
            "batch 115's loss: 2.3114824295043945\n",
            "batch 116's loss: 3.1959593296051025\n",
            "batch 117's loss: 2.0963988304138184\n",
            "batch 118's loss: 2.8575096130371094\n",
            "batch 119's loss: 2.3528411388397217\n",
            "batch 120's loss: 1.2228449583053589\n",
            "batch 121's loss: 2.3008360862731934\n",
            "batch 122's loss: 2.213132381439209\n",
            "batch 123's loss: 1.3276982307434082\n",
            "batch 124's loss: 2.224219799041748\n",
            "batch 125's loss: 2.1482064723968506\n",
            "batch 126's loss: 1.5050833225250244\n",
            "batch 127's loss: 1.2941946983337402\n",
            "batch 128's loss: 0.3856825828552246\n",
            "batch 129's loss: 0.877316415309906\n",
            "batch 130's loss: 0.7926799058914185\n",
            "batch 131's loss: 1.9814060926437378\n",
            "batch 132's loss: 1.9163395166397095\n",
            "batch 133's loss: 0.9361170530319214\n",
            "batch 134's loss: 1.2350395917892456\n",
            "batch 135's loss: 3.4166829586029053\n",
            "batch 136's loss: 1.4874917268753052\n",
            "batch 137's loss: 1.8164336681365967\n",
            "batch 138's loss: 1.7638856172561646\n",
            "batch 139's loss: 2.4291605949401855\n",
            "batch 140's loss: 1.1630949974060059\n",
            "batch 141's loss: 2.6608095169067383\n",
            "batch 142's loss: 2.503605604171753\n",
            "batch 143's loss: 1.3238943815231323\n",
            "batch 144's loss: 1.9254682064056396\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d75760c0f4cc>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# KoBERT 모델과 토크나이저 로드\n",
        "model = BertModel.from_pretrained('monologg/kobert').to(device)\n",
        "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
        "\n",
        "# 모든 파라미터 동결\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# LoRA 레이어 정의\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, input_dim, rank=8, alpha=16, dropout=0.05):\n",
        "        super(LoRALayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = input_dim\n",
        "        self.down_project = nn.Linear(input_dim, rank, bias=False)\n",
        "        self.up_project = nn.Linear(rank, input_dim, bias=False)\n",
        "        self.dropout = nn.Dropout(p=dropout)  # Dropout 추가\n",
        "\n",
        "\n",
        "        # Scaling Factor 추가\n",
        "        self.alpha = alpha\n",
        "        self.scaling = self.alpha / rank  # 스케일링 계산\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.down_project(x)  # 차원 축소\n",
        "        x = self.dropout(x)       # Dropout 적용\n",
        "        return self.scaling * self.up_project(x)  # 스케일링 및 차원 복원\n",
        "\n",
        "# LoRA 레이어 초기화\n",
        "lora_layer = LoRALayer(input_dim=768, rank=16).to(device)\n",
        "\n",
        "# 데이터셋 정의\n",
        "class LiteraryMLMDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=512, mask_prob=0.15):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.mask_prob = mask_prob\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "\n",
        "        # MLM: 마스킹 생성\n",
        "        labels = input_ids.clone()\n",
        "        rand = torch.rand(input_ids.shape)\n",
        "        mask_arr = (rand < self.mask_prob) * (input_ids != self.tokenizer.cls_token_id) * \\\n",
        "                   (input_ids != self.tokenizer.sep_token_id) * (input_ids != self.tokenizer.pad_token_id)\n",
        "\n",
        "        # 마스킹된 위치를 [MASK] 토큰으로 대체\n",
        "        input_ids[mask_arr] = self.tokenizer.mask_token_id\n",
        "\n",
        "        # 마스크된 위치의 정답은 그대로 남기고, 나머지는 -100으로 설정 (loss 계산 제외)\n",
        "        labels[~mask_arr] = -100\n",
        "        return {\n",
        "            'input_ids': input_ids.to(device),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze().to(device),\n",
        "            'labels': labels.to(device)\n",
        "        }\n",
        "\n",
        "# DataLoader 생성\n",
        "texts = df['origin_text'].tolist()\n",
        "dataset = LiteraryMLMDataset(texts, tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# 옵티마이저 설정 (LoRA 레이어만 학습)\n",
        "vocab_size = tokenizer.vocab_size\n",
        "prediction_layer = nn.Linear(lora_layer.output_dim, vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(lora_layer.parameters()) + list(prediction_layer.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=0.1\n",
        ")\n",
        "\n",
        "# 학습 루프\n",
        "model.train()\n",
        "lora_layer.train()\n",
        "prediction_layer.train()\n",
        "\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    i = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        # 프리트레인된 KoBERT 모델에서 임베딩 추출\n",
        "        with torch.no_grad():  # KoBERT의 파라미터는 업데이트하지 않음\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            pretrained_embedding = outputs.last_hidden_state  # [batch_size, sequence_length, hidden_size]\n",
        "\n",
        "        # LoRA 레이어 통과\n",
        "        lora_embedding = lora_layer(pretrained_embedding)\n",
        "\n",
        "        # 프리트레인된 임베딩 +  LoRA 임베딩\n",
        "        combined_embedding = pretrained_embedding + lora_embedding\n",
        "\n",
        "        # 예측 layer에 위에서 계산된 임베딩 삽입\n",
        "        predictions = prediction_layer(combined_embedding)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "        loss = loss_fn(predictions.view(-1, vocab_size), labels.view(-1))\n",
        "\n",
        "        # 역전파 및 옵티마이저 단계\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        i += 1\n",
        "\n",
        "        print(f\"batch {i}'s loss: {loss}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0D2TJqBS69T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}